# Homework 1: Data about "Data"

In his essay, "Data before the Fact," Daniel Rosenberg explores the history of the term "data" using the *Oxford English Dictionary (OED)* and the **corpus**––a fancy word for a set or collection of files––of books digitized by Google. In this exercise, we're going to practice working with the OED and the GoogleNgram viewer to better understand some of the ways it might be used in research as well as some of the arguments that we can make *about* this tool. We'll end with a little sneak preview of another database.

There are three short parts to this exercise. 

## I.  "Data" in the *Oxford English Dictionary*

Look up the term "data" (and the singular, "datum") in the [*Oxford English Dictionary* (OED)](https://www.oed.com/?tl=true). Unlike most dictionaries, the *OED* gives you historical definitions of words in the past (and present) usage.  drawing on records of the words in usage in print. 

+ Visit the *Oxford English Dictionary* (OED)](https://www.oed.com/?tl=true)

+ Type in "data" and "datum" and explore the different historical. What do you notice? What does (and has) "data" meant? When?

+ Take a look at the quotations and other supplementary information that the OED supplies. Try clicking on the grey "..." icon next to each quotation.  Poke around the interface? What do you notice about the kinds of sources? The quotations themselves?  What else can we glean? What *don't* we know?

### What are we searching when we search the OED?

+ Take a look at the [history of the OED](https://www.oed.com/information/about-the-oed/history-of-the-oed/) page and the *Examining the OED* project list of ["top sources"](https://oed.hertford.ox.ac.uk/quotations/outline/top-sources/). What do you notice about the kinds of materials that went into the making of the OED? What implications might I have for the way we use the tool?

+ Finally, write up a few sentences reflection on what you've found. You can use screenshots.

## II. "Data" in GoogleBooks 

Now let's turn to Google Ngrams!  "**Ngrams**" is a term for one, two, three, etc... number of word phrases (with "n" being a placeholder for a number). So a 1-gram is a single word, a 2-gram  is a two-word phrase, etc.

1. Visit the [Google Ngram Viewer](https://books.google.com/ngrams).

2. Try to enter in "data."  What do you notice?

3. Try to change the dates to the parameters from Rosenberg's article?

4. Try one of Rosenberg's other search terms, "he sobbed" vs "she sobbed" or "zombie" vs "vampire." What do you notice?

### What are we searching when we search GoogleBooks?

5. Now change the corpus ––this is the collection of digitized books that the n-gram viewer searches–– from "English" to  "American English" by selecting it from the dropdown menu. What happened? What do you notice about the difference in the results? What implications might this have for the kind of arguments we can make with this data?

6. Change the corpus to "British English" and "English Fiction." What do you notice about the results displayed each time?

7. What *is* "British English" or "English Fiction"? That is, can you figure out out what works/objects/things the Ngram Viewer is drawing on?

+ Find the section Google-Ngram Viewer's [information page](https://books.google.com/ngrams/info#) where these different corpuses are defined. How are they defined?  What implications does this have?

8. Finally, write up a few sentence reflecting on what you've found. You can include screenshots of your exploratory research with the Ngram Viewer if that helps. 


## III. "Data" in *Eighteenth-Century Collections Online (ECCO)** 

Rosenberg doesn't just use the OED, the Google Ngram Viewer and Google Books. What were some options Rosenberg makes about the limitations of Google Books in thinking about word usage in the eras before the 19th century?

9. Just to get our feet wet, search "data" in [Eighteenth-Century Collections Online (ECCO)] (log in using your Wes ID here: [https://library.princeton.edu/resource/3745](https://library.princeton.edu/resource/3745) What might Rosenberg have to do to this data to make it so that he can make the queries that he makes? (You might look at one more recent project that has done this: the [ECCO TCT transcription project](https://github.com/Early-Modern-OCR/TCP-ECCO-texts))

